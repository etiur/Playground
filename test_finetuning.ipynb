{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to finetune HuggingFace models on text data of any size and format with custom splitting (not random)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A way to handle text data of any size and format with custom split because random splitting is not recommended for protein sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "import torch\n",
    "import numpy as np\n",
    "from Bio import SeqIO\n",
    "from datasets import Dataset, DatasetDict\n",
    "from sklearn.model_selection import GroupKFold\n",
    "import pandas as pd\n",
    "from typing import Sequence\n",
    "from sklearn.utils import shuffle\n",
    "## https://github.com/huggingface/notebooks/blob/main/examples/text_classification.ipynb\n",
    "## https://github.com/huggingface/notebooks/blob/main/examples/protein_language_modeling-tf.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You need to label the target values as labels so Trainer can recognize it.  \n",
    "Dataset can actually be used for any usecases with large files it doesn't depend on transformers.  \n",
    "Although you would need to use PyTorch Dataloader to transform it into batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fasta_generator(fasta_file: str=\"whole_sequence.fasta\"):\n",
    "    with open(fasta_file, 'r') as f:\n",
    "        seqs = SeqIO.parse(f, 'fasta')\n",
    "        for seq in seqs:\n",
    "            yield {\"id\":seq.id, \"seq\":str(seq.seq)}\n",
    "\n",
    "b = Dataset.from_generator(fasta_generator, gen_kwargs={\"fasta_file\":\"whole_sequence.fasta\"})\n",
    "y = np.random.randint(0, 2, size=len(b))\n",
    "dataset = b.add_column(\"labels\", y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom spliting with indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_cluster_info(file_path: str) -> dict[str | int, list[str|int]]:\n",
    "\t\"\"\"\n",
    "\tRead the cluster information from a tsv file generated by MMSeqs2 function.\n",
    "\tThe sequences are clusterized at 30% sequence identity. So sequences in different clusters are at most 30% identical.\n",
    "\t\"\"\"\n",
    "\tcluster_info = {}\n",
    "\twith open(file_path, \"r\") as f:\n",
    "\t\tlines = [x.strip() for x in f.readlines()]\n",
    "\tfor x in lines:\n",
    "\t\tX = x.split(\"\\t\")\n",
    "\t\tif X[0] not in cluster_info:\n",
    "\t\t\tcluster_info[X[0]] = []\n",
    "\t\tcluster_info[X[0]].append(X[1])\n",
    "\treturn cluster_info\n",
    "\n",
    "def get_group_index(cluster_info, index: Sequence[str | int]) -> np.ndarray:\n",
    "\t\"\"\"\n",
    "\tNow for each sample in the data, assign a group using the cluster info dictionary.\n",
    "\tThe groups will be the keys of the cluster info.\n",
    "\n",
    "\tindex should be the same as the cluster_info values.\n",
    "\t\"\"\"\n",
    "\tgroup = []\n",
    "\tfor x in index:\n",
    "\t\tfor key, value in cluster_info.items():\n",
    "\t\t\tif x in value:\n",
    "\t\t\t\tgroup.append(key)\n",
    "\t\t\t\tbreak\n",
    "\tgroup = np.array(group)\n",
    "\treturn group\n",
    "\n",
    "def split(X: Sequence[int | str] | pd.DataFrame, y: Sequence[int] | None=None, \n",
    "            groups: Sequence[str|int] | None = None) -> list[tuple[np.ndarray, np.ndarray]]:\n",
    "    \"\"\"\n",
    "    Split the data into train and test sets.\n",
    "    \"\"\"\n",
    "    group_kfold = GroupKFold(n_splits=5)\n",
    "    fold = list(group_kfold.split(X, y, groups=groups))\n",
    "    return fold\n",
    "\n",
    "def get_fold(fold: list[np.ndarray], dataset: Dataset, fold_num: int) -> DatasetDict:\n",
    "    \"\"\"\n",
    "    Get the train and test sets for the given fold.\n",
    "    \"\"\"\n",
    "    train_idx, test_idx = fold[fold_num]\n",
    "    train = dataset.select(train_idx).shuffle(43)\n",
    "    test = dataset.select(test_idx).shuffle(43)\n",
    "    return DatasetDict({\"train\":train, \"test\":test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'seq', 'labels'],\n",
       "        num_rows: 117\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'seq', 'labels'],\n",
       "        num_rows: 30\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster = read_cluster_info(\"resultsDB_clu.tsv\")\n",
    "group = get_group_index(cluster, dataset[\"id\"])\n",
    "fold = split(dataset, y, group)\n",
    "fold_0 = get_fold(fold, dataset, 0)\n",
    "fold_0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the large language models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "disable_pgu = True\n",
    "device = \"cuda:0\" if torch.cuda.is_available() and not disable_pgu else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of EsmForSequenceClassification were not initialized from the model checkpoint at facebook/esm2_t6_8M_UR50D and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\"facebook/esm2_t6_8M_UR50D\", num_labels=2)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/esm2_t6_8M_UR50D\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d758a0fd5dd64c1f99369b54efb02b49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/117 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd131fcc52fc4d258fd893e697b193a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/30 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fold_0[\"train\"] = fold_0[\"train\"].map(lambda examples: tokenizer(examples[\"seq\"], return_tensors=\"np\",padding=True, truncation=True), batched=True)\n",
    "fold_0[\"test\"] = fold_0[\"test\"].map(lambda examples: tokenizer(examples[\"seq\"], return_tensors=\"np\",padding=True, truncation=True), batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'seq', 'labels', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 117\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'seq', 'labels', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 30\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fold_0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the training arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer, EarlyStoppingCallback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can play with these values to see which one returns the highest performance (see [hyperparameter search from huggingface](https://huggingface.co/docs/setfit/how_to/hyperparameter_optimization))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 8e-5\n",
    "bs = 1\n",
    "epochs = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set use_cpu to False when you wan to use GPUs (it will automatically use GPUs), when f16 is True it will only use GPUs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = TrainingArguments('outputs', learning_rate=lr, warmup_ratio=0.2, lr_scheduler_type='cosine', fp16=False if device==\"cpu\" else True,\n",
    "    evaluation_strategy=\"epoch\", per_device_train_batch_size=bs, per_device_eval_batch_size=bs*2,\n",
    "    num_train_epochs=epochs, weight_decay=0.01, report_to=['mlflow'],\n",
    "    load_best_model_at_end=True, metric_for_best_model=\"matthews_correlation\", \n",
    "    save_total_limit=2, save_strategy=\"epoch\", seed=3242342, gradient_accumulation_steps=4, \n",
    "    use_cpu=True if device==\"cpu\" else False) \n",
    "\n",
    "## cosine will set it to cosine and then we have a learning rate\n",
    "## weight decay for the Adam -> this is fast.Ai does\n",
    "## fp16 is half precision -> mixed training (using fp32 and fp16)\n",
    "## save_total_limit to 2 -> so only 2 models will be saved\n",
    "## Save the report to mlflow\n",
    "# LR finder does not give reliable results for Transformers models https://github.com/huggingface/transformers/issues/16013"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model and evaluate the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "import mlflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use your own function as an evaluation metric -> then you have to retun as a dictionary {metric_name: metric_score}  \n",
    "Or you can use the evaluate library from hugging face to load different functions: [evaluate](https://huggingface.co/docs/evaluate/a_quick_tour)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_classification_metrics(eval_pred):\n",
    "    metrics = [\"accuracy\", \"f1\", \"matthews_correlation\", \"precision\", \"recall\"]\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "\n",
    "    loaded = {metric:evaluate.load(metric) for metric in metrics}\n",
    "    results = {metric: loaded[metric].compute(predictions=predictions, references=labels)[metric] \n",
    "               for metric in metrics}\n",
    "\n",
    "    # the predictions from the models are logits (it also returns the labels, \n",
    "    # it also returns loss, attentions and hidden state but that is the classification model, for evalaution Trainer will only \n",
    "    # return logits and labels)\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of EsmForSequenceClassification were not initialized from the model checkpoint at facebook/esm2_t6_8M_UR50D and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(model, args, train_dataset=fold_0['train'], eval_dataset=fold_0['test'], # we need to pass tokenized datasets\n",
    "                  tokenizer=tokenizer, compute_metrics=compute_classification_metrics,\n",
    "                  callbacks=[EarlyStoppingCallback(early_stopping_patience=2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of EsmForSequenceClassification were not initialized from the model checkpoint at facebook/esm2_t6_8M_UR50D and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62199f45d217431c9970997fd8dbe5e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/232 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44e7ece3b99449cda4e95fa4245d5aaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6930113434791565, 'eval_accuracy': 0.5, 'eval_f1': 0.6511627906976744, 'eval_matthews_correlation': -0.0890870806374748, 'eval_precision': 0.5185185185185185, 'eval_recall': 0.875, 'eval_runtime': 15.6809, 'eval_samples_per_second': 1.913, 'eval_steps_per_second': 0.957, 'epoch': 0.99}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46ebda32afa5489b912b2fcff98561c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ruite\\miniforge3\\envs\\BioML\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6964237093925476, 'eval_accuracy': 0.4666666666666667, 'eval_f1': 0.0, 'eval_matthews_correlation': 0.0, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_runtime': 16.4017, 'eval_samples_per_second': 1.829, 'eval_steps_per_second': 0.915, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "874dc1edf0614de3b8efdc2e536929a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ruite\\miniforge3\\envs\\BioML\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6956890225410461, 'eval_accuracy': 0.4666666666666667, 'eval_f1': 0.0, 'eval_matthews_correlation': 0.0, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_runtime': 15.4504, 'eval_samples_per_second': 1.942, 'eval_steps_per_second': 0.971, 'epoch': 2.99}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a6eae8c3d2446d6847f635a9acd3c44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6947107315063477, 'eval_accuracy': 0.4666666666666667, 'eval_f1': 0.0, 'eval_matthews_correlation': 0.0, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_runtime': 15.7289, 'eval_samples_per_second': 1.907, 'eval_steps_per_second': 0.954, 'epoch': 3.97}\n",
      "{'train_runtime': 583.9581, 'train_samples_per_second': 0.801, 'train_steps_per_second': 0.397, 'train_loss': 0.7043541875378839, 'epoch': 3.97}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ruite\\miniforge3\\envs\\BioML\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=232, training_loss=0.7043541875378839, metrics={'train_runtime': 583.9581, 'train_samples_per_second': 0.801, 'train_steps_per_second': 0.397, 'train_loss': 0.7043541875378839, 'epoch': 3.97})"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.end_run()\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03fca794acd847d88b0182b060997fd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6928602457046509, 'eval_accuracy': 0.5333333333333333, 'eval_f1': 0.6956521739130436, 'eval_matthews_correlation': 0.0, 'eval_precision': 0.5333333333333333, 'eval_recall': 1.0, 'eval_runtime': 14.71, 'eval_samples_per_second': 2.039, 'eval_steps_per_second': 1.02, 'epoch': 3.83}\n"
     ]
    }
   ],
   "source": [
    "metrics = trainer.evaluate()\n",
    "print(metrics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bioml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
